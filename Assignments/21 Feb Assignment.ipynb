{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4f743ea-27c9-4dbe-b735-1f56e663a431",
   "metadata": {},
   "source": [
    "![](Pw.png)\n",
    "## Name:                       Mahfuz Ronnie\n",
    "## Course Name:                Data Science Masters\n",
    "## Batch Name:                ‘Impact Batch’ English\n",
    "## Assignment Name:            21st Feb Flask\n",
    "## Submission Date:            27th March 2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54cc819-2730-47ef-97b6-f540277ea58c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88996583-9200-4efc-b44a-e7b20fcfe520",
   "metadata": {},
   "source": [
    "# Q1. What is web scraping? Why is it used? Give three areas where web scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4113dab3-bd01-41fd-bf3e-77d329a4ab80",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Web scraping refers to the extraction of data from a website. This information is collected and then exported into a format that is more useful for the user. Be it a spreadsheet or an API.\n",
    "### Web scraping is a valuable tool for businesses and individuals to gather information, analyze data, and make informed decisions. It is for various purposes \n",
    "* Data Collection\n",
    "* Market Research\n",
    "* Lead Generation\n",
    "* Content Creation\n",
    "* Price monitoring \n",
    "\n",
    "### Three areas where web scraping used to get the data \n",
    "* E-commerce: Web scraping is used by online retailers to collect product information, pricing, and reviews from competitors' websites. This information can be used to adjust their own prices and product offerings, as well as to keep track of the competition.\n",
    "\n",
    "* Research and Analytics: Web scraping is used in research and analytics to collect data from various sources, including social media platforms, news websites, and government websites. This data can be used to identify trends, monitor sentiment, and gain insights into consumer behavior.\n",
    "\n",
    "* Marketing: Web scraping is used in marketing to collect data on potential customers, such as email addresses and phone numbers, which can be used for lead generation. It can also be used to monitor online mentions of a brand or product, which can help companies to identify and address any negative sentiment or issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47d8ac4-bf90-437a-bf67-85c7b196a35d",
   "metadata": {},
   "source": [
    "# Q2. What are the differnet methods used for web scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034b4cac-41f4-4072-9768-bb09ceacafde",
   "metadata": {},
   "source": [
    "### There are several methods used for web scraping, the methods used for web scraping depends on the specific requirements of the project, the available resources, and the technical skills of the scraper. here is some example-\n",
    "* Using web scraping tools\n",
    "* Using APIs\n",
    "* Manual scraping\n",
    "* Using browser extensions\n",
    "* Using machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8123adc2-e975-4e68-b051-ba040180c9b1",
   "metadata": {},
   "source": [
    "# Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fec5b5e-efc2-45a1-95c9-2676ce639f56",
   "metadata": {},
   "source": [
    "### Beautiful Soup is a Python library that is used for web scraping purposes. Beautiful Soup provides a simple API for traversing the parse tree of an HTML or XML document, and it can be used to extract specific elements and attributes from the document.\n",
    "### Beautiful Soup is used for web scraping because it allows developers to automate the process of extracting data from websites. It can handle messy and inconsistent HTML code, and it can parse the structure of the document to extract specific data points. This can be particularly useful when scraping large amounts of data from websites."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0369d6-aeac-4139-9616-a9f0c0e03053",
   "metadata": {},
   "source": [
    "# Q4. Why is flask used in this web scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc92108-f64f-435c-ae75-83680b7e1095",
   "metadata": {},
   "source": [
    "### Flask is a web framework for Python that is commonly used to build web applications, APIs, and other web-based projects. Flask can be used to create a web interface that allows users to interact with the web scraping tool. Flask is used in web scraping project beacuse \n",
    "* Flask can be used to create a web interface that allows users to input search parameters, specify the data they want to scrape, and view the results of the scraping process.\n",
    "* Flask can be used to run the web scraper as a background process. This allows users to submit a scraping request, and then continue to use the web interface while the scraper runs.\n",
    "* Flask can be used to manage the data that is scraped from websites. This includes storing the data in a database, processing the data, and generating reports or visualizations based on the data.\n",
    "* Flask can be used to implement access control and security measures for the web scraping tool. This includes implementing user authentication, preventing unauthorized access to the tool, and encrypting sensitive data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c606d3f9-3a73-4447-be56-3d05492888ce",
   "metadata": {},
   "source": [
    "# Q5. Write the names of AWS services used in this project. Also, explain the use of each sevice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48065009-a5dc-45fb-b42e-8bc5a599e368",
   "metadata": {},
   "source": [
    "### Web scraping is a process of collecting and extracting data from websites automatically. AWS provides a range of services that can be used to facilitate web scraping.\n",
    "* Amazon EC2 (Elastic Compute Cloud): EC2 is a scalable computing service that allows users to launch virtual servers, also known as instances, in the cloud. EC2 can be used to run web scraping scripts, as it provides scalable computing resources that can handle the processing requirements of the scripts.\n",
    "\n",
    "* Amazon S3 (Simple Storage Service): S3 is an object storage service that allows users to store and retrieve data from the cloud. S3 can be used to store the scraped data in a centralized location, which can be accessed by other AWS services or external applications.\n",
    "\n",
    "* Amazon Lambda: Lambda is a serverless computing service that allows developers to run code without provisioning or managing servers. Lambda can be used to run the web scraper in a serverless environment, which can reduce the cost and complexity of the infrastructure required to run the tool.\n",
    "\n",
    "* Amazon API Gateway: API Gateway is a fully managed service that makes it easy to create, deploy, and manage APIs at scale. API Gateway can be used to expose the web scraping functionality as a RESTful API, which can be accessed by other applications or services.\n",
    "\n",
    "* AWS Glue: Glue is a fully managed ETL (extract, transform, and load) service that makes it easy to move data between data stores. Glue can be used to transform the scraped data into a format that is suitable for analysis and reporting.\n",
    "\n",
    "* Amazon Comprehend: Comprehend is a natural language processing service that can be used to extract insights from the scraped data. Comprehend can be used to extract entities, sentiment, and other useful information from the scraped data.\n",
    "\n",
    "* Amazon Rekognition: Rekognition is a computer vision service that can be used to analyze and extract information from images and videos. Rekognition can be used to analyze images and videos scraped from websites.\n",
    "\n",
    "* Amazon CloudWatch: CloudWatch is a monitoring service that provides real-time monitoring of AWS resources and applications. CloudWatch can be used to monitor the performance of the web scraper and detect any issues that might arise during the scraping process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
